### preamble
rm(list = ls())
wd = 'C:\\Users\\KLN\\Documents\\DTL\\computerLab\\day2'
dd = 'C:\\Users\\KLN\\Documents\\DTL\\computerLab\\day2\\data'
setwd(wd)

# packages
library(tm)
# if in doubt
help(package=tm)

# build corpus
gcorpus  <- Corpus(DirSource(dd), readerControl = list(language="lat"))
gcorpus
names(gcorpus)# subsets: documents
gcorpus[1]# subset 1: document 1
gcorpus[[1]]# access subset 1
gcorpus[[1]][1]# content
gcorpus[[1]][2]# metadata
# or
gcorpus['Acts.txt']# subset 1: document 1
gcorpus[['Acts.txt']]# access subset 1
gcorpus[['Acts.txt']]$content# content
gcorpus[['Acts.txt']]$meta# metadata
# combined
gcorpus[[1]]$meta$id# document name
gcorpus[['Acts.txt']]$content[1:10]# lines
# for more
?Corpus

# save corpus object
save(gcorpus, file = "gcorpus.RData")
rm(gcorpus)
load("gcorpus.RData")
# save workspace
save.image(file = "gcorpusImage.RData")
rm(list = ls())
load("gcorpusImage.RData")

# preprocess %%% check transformations
gcorpus <- tm_map(gcorpus, removeNumbers)
gcorpus <- tm_map(gcorpus, removePunctuation)
gcorpus <- tm_map(gcorpus, content_transformer(tolower))
  # %%% introduce nchar
    # nchar(gcorpus, type = "chars", allowNA = FALSE, keepNA = NA)
gcorpus <- tm_map(gcorpus, removeWords, stopwords("english"))
  # %%% discuss stopword
    # stopwords(kind = "en")
gcorpus <- tm_map(gcorpus, stripWhitespace)
names(gcorpus)
# plain text formatting for matrix representation
gcorpusPv <- tm_map(gcorpus, PlainTextDocument)

# a little regex
names(gcorpus) <- gsub("\\..*","",names(gcorpus))# match all '.' and 'any character' and replace with ''
gcorpus[[1]][[2]][5]

# dtm
gcDtm <- DocumentTermMatrix(gcorpusPv)
gcDtm
colnames(gcDtm)
rownames(gcDtm) <- names(gcorpus)
# reduce dimensions by removing sparse entries
gcDtm <- removeSparseTerms(gcDtm, 0.6)# maximal sparcity = two document
inspect(gcDtm[,"god"])


# function for setting minimum representation of documents
docsparse <- function(mindocs,dtm){
  n = length(row.names(dtm))
  sparse <- 1 - mindocs/n;
  dtmreduce <- removeSparseTerms(dtm, sparse)
  return(dtmreduce)
}

gcDtm <- docsparse(2,gcDtm)



# frequent words and associations
findFreqTerms(gcDtm["Matthew",], 100)
findAssocs(gcDtm, "jesus", 0.93) 

# tf-idf weighting
  # %%% show weighting factors and schemes + link to normalization 
gcDtmTfidf <- DocumentTermMatrix(gcorpusPv,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
  # alternatively
  gcDtmTfidf2 <- weightTfIdf(gcDtm, normalize = FALSE)
rownames(gcDtmTfidf) <- names(gcorpus)
  #%%% what happened to god?
  inspect(gcDtmTfidf[,"god"]) 
# remove sparse items
gcDtmTfidf <- removeSparseTerms(gcDtmTfidf, 0.6)# maximal sparcity = two documents



########### DOCUMENT CLUSTERING

shell.exec("https://cran.r-project.org/web/views/Cluster.html")

### partional prototype-based exclusive clustering: k-means
## quick-n-dirty k-means on euclidean distance*
# for reproducibility 
set.seed(1234)
gcmatrix <- as.matrix(gcDtmTfidf)
# length-normalize the vectors (Manning, p. 121)
norm_eucl <- function(m) m/apply(m, MARGIN=1, FUN=function(x) sum(x^2)^.5)#
  # %%% explain function object
gcmatrixNorm <- norm_eucl(gcmatrix)

# 2 sub-groups or clusters
k = 2
gccl <- kmeans(gcmatrixNorm, k)
# inspect cluster object
gccl
# classification
gccl$cluster
# goodness of the classification
  # %%% explain BSS/TSS
as.numeric(gccl[6])/as.numeric(gccl[3])# c
# plot clusters using the first 2 principal components
plot(prcomp(gcmatrixNorm)$x, col=gccl$cl)
text(prcomp(gcmatrixNorm)$x[,1],prcomp(gcmatrixNorm)$x[,2],rownames(gcmatrixNorm))

# vary parameters for most readable graph
library(cluster) 
clusplot(gcmatrixNorm, gccl$cl, color=TRUE, shade=TRUE, 
         labels=2, lines=0)

# Centroid Plot against 1st 2 discriminant functions
library(fpc)
plotcluster(gcmatrixNorm, gccl$cl)


# find frequent terms and associations in clusters 
findFreqTerms(gcDtm[gccl$cluster == 1,], 50)
findAssocs(gcDtm[gccl$cluster == 2,], "god", 0.95)# should only be used for larger corpora (not at all for one or two document clusters)


## k-means more principled
## deciding number of cluster k

# graphical approach: plot of total within-groups sums of squares against number of k
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}
maxk = nrow(gcmatrixNorm)-1
wssplot(gcmatrixNorm,nc = maxk) 

# optimization: choose optimal k 
#install.packages("NbClust")
library(NbClust)
set.seed(1234)
numClust <- NbClust(gcmatrixNorm, min.nc=2, max.nc=4, method="kmeans")
  # %%% explain curse of dimensionality (small sample and negative eigenvalues)
table(numClust$Best.n[1,]) # jury
